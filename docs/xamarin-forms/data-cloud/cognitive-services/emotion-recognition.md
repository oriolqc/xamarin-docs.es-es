---
title: Reconocimiento de expresión mediante la API de cara
description: La API de cara toma una expresión facial en una imagen como entrada y devuelve los datos que incluyen los niveles de confianza a través de un conjunto de emociones para cada cara de la imagen. En este artículo se explica cómo usar la API de cara a reconocer emociones, para calificar una aplicación de Xamarin.Forms.
ms.prod: xamarin
ms.assetid: 19D36A7C-E8D8-43D1-BE80-48DE6C02879A
ms.technology: xamarin-forms
author: davidbritch
ms.author: dabritch
ms.date: 05/10/2018
ms.openlocfilehash: 4dc04cb077b894b255eb496b2cb2983626573897
ms.sourcegitcommit: b0a1c3969ab2a7b7fe961f4f470d1aa57b1ff2c6
ms.translationtype: MT
ms.contentlocale: es-ES
ms.lasthandoff: 05/10/2018
---
# <a name="emotion-recognition-using-the-face-api"></a>Reconocimiento de expresión mediante la API de cara

_La API de cara toma una expresión facial en una imagen como entrada y devuelve los datos que incluyen los niveles de confianza a través de un conjunto de emociones para cada cara de la imagen. En este artículo se explica cómo usar la API de cara a reconocer emociones, para calificar una aplicación de Xamarin.Forms._

## <a name="overview"></a>Información general

La API de cara puede realizar emociones de detección para detectar ira, contempt, disgust, temor, satisfacción, neutral, tristeza y sorpresa, en una expresión facial. Universalmente y transculturalmente estas emociones se comunican a través de las mismas expresiones faciales básicas. Así como devolver un resultado de la expresión de una expresión facial, la API de cara puede también devuelve un cuadro de límite de caras detectados. Tenga en cuenta que se debe obtener una clave de API para usar la API de cara. Esto se puede obtener en [intente cognitivos servicios](https://azure.microsoft.com/try/cognitive-services/?api=face-api).

Reconocimiento de emoción puede realizarse a través de una biblioteca de cliente y una API de REST. En este artículo se centra en la ejecución del reconocimiento de emoción a través de la API de REST. Para obtener más información acerca de la API de REST, consulte [API de REST de cara](https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236).

La API de cara también puede utilizarse para reconocer las expresiones faciales de personas de vídeo y puede devolver un resumen de sus emociones. Para obtener más información, consulte [cómo analizar los vídeos en tiempo real](/azure/cognitive-services/face/face-api-how-to-topics/howtoanalyzevideo_face/).

Para obtener más información acerca de la API de cara, consulte [API cara](/azure/cognitive-services/face/overview/).

## <a name="authentication"></a>Autenticación

Todas las solicitudes realizadas a la API de cara requiere una clave de API que se debe especificar como el valor de la `Ocp-Apim-Subscription-Key` encabezado. En el ejemplo de código siguiente se muestra cómo agregar la clave de API para el `Ocp-Apim-Subscription-Key` encabezado de una solicitud:

```csharp
public FaceRecognitionService()
{
  _client = new HttpClient();
  _client.DefaultRequestHeaders.Add("ocp-apim-subscription-key", Constants.FaceApiKey);
}
```

Error al pasar una clave de API válida a la API de cara se producirá un error de 401 respuesta.

## <a name="performing-emotion-recognition"></a>Realizar el reconocimiento de emociones

Reconocimiento emociones se realiza mediante la realización de una solicitud POST que contiene una imagen a la `detect` API en `https://[location].api.cognitive.microsoft.com/face/v1.0`, donde `[location]]` es la región que se utiliza para obtener la clave de API. Los parámetros de solicitud opcionales son:

- `returnFaceId` : si se deben devolver faceIds de las caras detectadas. El valor predeterminado es `true`.
- `returnFaceLandmarks` : si se deben devolver los hitos de la cara de las caras detectadas. El valor predeterminado es `false`.
- `returnFaceAttributes` : si se va a analizar y devolver uno o varios especifican enfrentan a atributos. Atributos de cara admitidos incluyen `age`, `gender`, `headPose`, `smile`, `facialHair`, `glasses`, `emotion`, `hair`, `makeup`, `occlusion`, `accessories`, `blur`, `exposure`, y `noise`. Observe que el análisis de atributo de cara tiene costo adicional de cálculo y el tiempo.

Contenido de la imagen se debe colocar en el cuerpo de la solicitud POST como una dirección URL o datos binarios.

> [!NOTE]
> Formatos de archivo de imagen admitidos son JPEG, PNG, GIF y BMP, y el tamaño de archivo permitido es de 1KB a 4MB.

En la aplicación de ejemplo, se invoca el proceso de reconocimiento emociones mediante una llamada a la `DetectAsync` método:

```csharp
Face[] faces = await _faceRecognitionService.DetectAsync(photoStream, true, false, new FaceAttributeType[] { FaceAttributeType.Emotion });
```

Esta llamada al método especifica la secuencia que contiene los datos de imagen, que se deben devolver faceIds, que no deben devolverse cara hitos y que se debe analizar la expresión de la imagen. También especifica que se devuelven los resultados como una matriz de `Face` objetos. A su vez, el `DetectAsync` método invoca el `detect` API de REST que realiza el reconocimiento de la expresión:

```csharp
public async Task<Face[]> DetectAsync(Stream imageStream, bool returnFaceId, bool returnFaceLandmarks, IEnumerable<FaceAttributeType> returnFaceAttributes)
{
  var requestUrl =
    $"{Constants.FaceEndpoint}/detect?returnFaceId={returnFaceId}" +
    "&returnFaceLandmarks={returnFaceLandmarks}" +
    "&returnFaceAttributes={GetAttributeString(returnFaceAttributes)}";
  return await SendRequestAsync<Stream, Face[]>(HttpMethod.Post, requestUrl, imageStream);
}
```

Este método genera un URI de solicitud y, a continuación, envía la solicitud a la `detect` API a través de la `SendRequestAsync` método.

> [!NOTE]
> Debe usar la misma región en las llamadas de API de cara que utiliza para obtener las claves de la suscripción. Por ejemplo, si ha adquirido las claves de la suscripción desde el `westus` región, el punto de conexión de detección de cara será `https://westus.api.cognitive.microsoft.com/face/v1.0/detect`.

### <a name="sending-the-request"></a>Enviar la solicitud

El `SendRequestAsync` método realiza la solicitud POST a la API de cara y devuelve el resultado como un `Face` matriz:

```csharp
async Task<TResponse> SendRequestAsync<TRequest, TResponse>(HttpMethod httpMethod, string requestUrl, TRequest requestBody)
{
  var request = new HttpRequestMessage(httpMethod, Constants.FaceEndpoint);
  request.RequestUri = new Uri(requestUrl);
  if (requestBody != null)
  {
    if (requestBody is Stream)
    {
      request.Content = new StreamContent(requestBody as Stream);
      request.Content.Headers.ContentType = new MediaTypeHeaderValue("application/octet-stream");
    }
    else
    {
      // If the image is supplied via a URL
      request.Content = new StringContent(JsonConvert.SerializeObject(requestBody, s_settings), Encoding.UTF8, "application/json");
    }
  }

  HttpResponseMessage responseMessage = await _client.SendAsync(request);
  if (responseMessage.IsSuccessStatusCode)
  {
    string responseContent = null;
    if (responseMessage.Content != null)
    {
      responseContent = await responseMessage.Content.ReadAsStringAsync();
    }
    if (!string.IsNullOrWhiteSpace(responseContent))
    {
      return JsonConvert.DeserializeObject<TResponse>(responseContent, s_settings);
    }
    return default(TResponse);
  }
  else
  {
    ...
  }
  return default(TResponse);
}
```

Si la imagen se proporciona a través de una secuencia, el método genera la solicitud POST ajustando el flujo de imágenes en un `StreamContent` instancia, lo que proporciona contenido HTTP basado en una secuencia. Como alternativa, si la imagen se proporciona a través de una dirección URL, el método genera la solicitud POST ajustando la dirección URL en una `StringContent` instancia, lo que proporciona contenido HTTP basado en una cadena.

La solicitud POST, a continuación, se envía a `detect` API. La respuesta es leer, deserializar y devuelve al método de llamada.

El `detect` API enviará el código de estado HTTP 200 (OK) en la respuesta, siempre que la solicitud es válida, lo que indica que la solicitud es correcta y que la información solicitada está en la respuesta. Para obtener una lista de posibles respuestas de error, consulte [API de REST de cara](https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236).

### <a name="processing-the-response"></a>Procesamiento de la respuesta

La respuesta de la API se devuelve en formato JSON. Los siguientes datos JSON muestran un mensaje de respuesta correcta típico que proporciona los datos solicitados por la aplicación de ejemplo:

```json
[  
   {  
      "faceId":"8a1a80fe-1027-48cf-a7f0-e61c0f005051",
      "faceRectangle":{  
         "top":192,
         "left":164,
         "width":339,
         "height":339
      },
      "faceAttributes":{  
         "emotion":{  
            "anger":0.0,
            "contempt":0.0,
            "disgust":0.0,
            "fear":0.0,
            "happiness":1.0,
            "neutral":0.0,
            "sadness":0.0,
            "surprise":0.0
         }
      }
   }
]
```

Un mensaje de respuesta correcta se compone de una matriz de entradas de cara clasificadas por el tamaño del rectángulo de cara en orden descendente, mientras que una respuesta vacía no indica ninguna caras detectados. Cada uno de ellos reconoce cara incluye una serie de atributos de cara opcional, que se especifican mediante el `returnFaceAttributes` argumento pasado a la `DetectAsync` método.

En la aplicación de ejemplo, la respuesta JSON se deserializa en una matriz de `Face` objetos. Al interpretar los resultados de la API de cara, las emociones detectado deben interpretarse como la emoción con la puntuación más alta, tal y como se normalizan las puntuaciones a suma a uno. Por lo tanto, la aplicación de ejemplo muestra la emoción reconocida con la puntuación más alta para los que se enfrentan detectado más grande en la imagen. Esto se consigue con el código siguiente:

```csharp
emotionResultLabel.Text = faces.FirstOrDefault().FaceAttributes.Emotion.ToRankedList().FirstOrDefault().Key;
```

Captura de pantalla siguiente muestra el resultado del proceso de reconocimiento emociones en la aplicación de ejemplo:

![](emotion-recognition-images/emotion-recognition.png "Reconocimiento de emociones")

## <a name="summary"></a>Resumen

Este artículo explica cómo usar la API de cara a reconocer emociones, para calificar una aplicación de Xamarin.Forms. La API de cara toma una expresión facial en una imagen como entrada y devuelve los datos que incluyen la confianza entre un conjunto de emociones para cada cara de la imagen.

## <a name="related-links"></a>Vínculos relacionados

- [Se enfrentan a API](/azure/cognitive-services/face/overview/).
- [Lista de tareas cognitivos servicios (ejemplo)](https://developer.xamarin.com/samples/xamarin-forms/WebServices/TodoCognitiveServices/)
- [Cara API de REST](https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236)
